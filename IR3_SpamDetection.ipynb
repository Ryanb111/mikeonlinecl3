{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "510b1d5d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcb9027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd,numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db05214f",
   "metadata": {},
   "source": [
    "# Data importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c56c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('spam.csv',encoding='utf-8',usecols=['v1','v2'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ae8df",
   "metadata": {},
   "source": [
    "# Checking missing values and eliminating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314a3eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1    0\n",
       "v2    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea32413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b82200b",
   "metadata": {},
   "source": [
    "# Converting String to Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b982d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "labelenc = LabelEncoder()\n",
    "\n",
    "x = cv.fit_transform(data['v2'])\n",
    "y = labelenc.fit_transform(data['v1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd54a9",
   "metadata": {},
   "source": [
    "# Spliting data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d3f8942",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00635ff",
   "metadata": {},
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9cfd985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a72433f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9763101220387652"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f9ee0",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "661d0f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email = cv.transform(['Congratulations!!!, You won Lottery of $1500000000 just now, just click on following link https://lottery.com/claim to claim your prize money'])\n",
    "labelenc.classes_[svc.predict(email)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cccf2b81-dbcc-4cb9-8edc-bc504fbef755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email = cv.transform(['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'])\n",
    "labelenc.classes_[svc.predict(email)[0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36e394f-40d2-4492-96b8-52b3854f3fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb468831-c2cb-403d-b2cf-3367302fdced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      1195\n",
      "           1       1.00      0.83      0.91       198\n",
      "\n",
      "    accuracy                           0.98      1393\n",
      "   macro avg       0.99      0.92      0.95      1393\n",
      "weighted avg       0.98      0.98      0.98      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4b8d3-8ee1-405a-a859-3ef09d6f2ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's break down the problem and the code step by step for clarity and a thorough understanding.\n",
    "\n",
    "---\n",
    "\n",
    "### **Problem Statement**\n",
    "**Goal**: Implement a program for **e-mail spam filtering** using a **text classification algorithm**. The program should:\n",
    "1. Take a dataset of labeled emails (spam or ham).\n",
    "2. Train a model to classify emails as \"spam\" or \"ham\" (non-spam) using a machine learning algorithm.\n",
    "3. Test the model's performance on unseen data.\n",
    "4. Classify new emails based on their text content.\n",
    "\n",
    "**Approach**:\n",
    "We use the **Support Vector Machine (SVM)** algorithm for classification, with text preprocessing techniques like tokenization and vectorization.\n",
    "\n",
    "---\n",
    "\n",
    "### **Detailed Explanation of Code**\n",
    "\n",
    "#### Step 1: Import Required Libraries\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "```\n",
    "- **`pandas`**: For data manipulation and analysis (loading and processing the dataset).\n",
    "- **`numpy`**: For numerical operations (optional, used implicitly by sklearn).\n",
    "- **`SVC`**: Support Vector Classifier, used for the classification task.\n",
    "- **`train_test_split`**: Splits the dataset into training and testing subsets.\n",
    "- **`CountVectorizer`**: Converts text data into a numerical feature matrix.\n",
    "- **`LabelEncoder`**: Encodes categorical labels (e.g., \"spam\" and \"ham\") into numerical values.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 2: Load the Dataset\n",
    "```python\n",
    "data = pd.read_csv('spam.csv', encoding='utf-8', usecols=['v1', 'v2'])\n",
    "```\n",
    "- **Purpose**: Load the dataset `spam.csv`.\n",
    "  - `v1`: The label (spam or ham).\n",
    "  - `v2`: The email text.\n",
    "- **`usecols=['v1', 'v2']`** ensures only the necessary columns are loaded.\n",
    "- **Dataset Example**:\n",
    "  ```\n",
    "      v1       v2\n",
    "  0   ham      Go until jurong point, crazy.. Available only in...\n",
    "  1   spam     Congratulations!!!, You won Lottery...\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 3: Data Exploration\n",
    "```python\n",
    "data.head()\n",
    "data.isnull().sum()\n",
    "```\n",
    "- **`data.head()`**: Displays the first 5 rows of the dataset.\n",
    "- **`data.isnull().sum()`**: Checks for missing values in the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 4: Handle Missing Data\n",
    "```python\n",
    "data.dropna(inplace=True)\n",
    "```\n",
    "- **Purpose**: Removes rows with missing values, ensuring clean data.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 5: Text Vectorization\n",
    "```python\n",
    "cv = CountVectorizer()\n",
    "x = cv.fit_transform(data['v2'])\n",
    "```\n",
    "- **Purpose**: Convert email text into numerical form for model training.\n",
    "- **`CountVectorizer`**:\n",
    "  - Breaks text into tokens (words).\n",
    "  - Creates a \"Bag of Words\" (BoW) representation, where each word is assigned a numerical count or frequency.\n",
    "- **Example**:\n",
    "  For emails:\n",
    "  ```\n",
    "  Email 1: \"dog bites man\"\n",
    "  Email 2: \"man bites dog\"\n",
    "  ```\n",
    "  The BoW representation:\n",
    "  ```\n",
    "  dog  man  bites\n",
    "  1    1    1  -> Email 1\n",
    "  1    1    1  -> Email 2\n",
    "  ```\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 6: Label Encoding\n",
    "```python\n",
    "labelenc = LabelEncoder()\n",
    "y = labelenc.fit_transform(data['v1'])\n",
    "```\n",
    "- **Purpose**: Encode categorical labels (\"spam\", \"ham\") into numerical values.\n",
    "  - Example:\n",
    "    - \"ham\" → 0\n",
    "    - \"spam\" → 1\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 7: Train-Test Split\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "```\n",
    "- **Purpose**: Split the data into training (75%) and testing (25%) sets.\n",
    "- **`random_state=42`**: Ensures reproducibility by fixing the randomness.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 8: Train the Model\n",
    "```python\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "```\n",
    "- **`SVC()`**: Initializes the Support Vector Classifier.\n",
    "- **`fit()`**: Trains the SVM model using the training data (`X_train` and `y_train`).\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 9: Evaluate the Model\n",
    "```python\n",
    "svc.score(X_test, y_test)\n",
    "```\n",
    "- **Purpose**: Computes the accuracy of the model on the test data.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 10: Predict New Emails\n",
    "```python\n",
    "email = cv.transform(['Congratulations!!!, You won Lottery of $1500000000...'])\n",
    "labelenc.classes_[svc.predict(email)[0]]\n",
    "```\n",
    "- **Purpose**: Classify a new email.\n",
    "  - The text is vectorized using the trained `CountVectorizer` (`cv.transform()`).\n",
    "  - `svc.predict(email)` predicts the label (0 or 1).\n",
    "  - `labelenc.classes_` maps the label back to the original class (\"ham\" or \"spam\").\n",
    "\n",
    "---\n",
    "\n",
    "#### Step 11: Classification Report\n",
    "```python\n",
    "y_pred = svc.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "- **Purpose**: Generate a detailed report of the model's performance, including:\n",
    "  - **Precision**: How many predicted \"spam\" emails are actually spam?\n",
    "  - **Recall**: How many actual spam emails were correctly predicted?\n",
    "  - **F1-Score**: The harmonic mean of precision and recall.\n",
    "\n",
    "---\n",
    "\n",
    "### **Theory: Support Vector Machine (SVM)**\n",
    "\n",
    "#### What is SVM?\n",
    "Support Vector Machine is a supervised learning algorithm used for classification tasks. It works by:\n",
    "1. Finding a hyperplane (decision boundary) that best separates classes (e.g., spam and ham).\n",
    "2. Maximizing the margin (distance) between the hyperplane and the nearest points from each class.\n",
    "\n",
    "#### Why SVM for Spam Filtering?\n",
    "- Effective in high-dimensional spaces (e.g., text data).\n",
    "- Handles linearly and non-linearly separable data.\n",
    "- Resistant to overfitting when the dataset is small.\n",
    "\n",
    "---\n",
    "\n",
    "### **Functions and Constructs Used**\n",
    "\n",
    "1. **`CountVectorizer`**:\n",
    "   - Converts text into numerical features using token counts.\n",
    "   - Commonly used in Natural Language Processing (NLP).\n",
    "\n",
    "2. **`LabelEncoder`**:\n",
    "   - Encodes categorical labels into numerical values.\n",
    "\n",
    "3. **`train_test_split`**:\n",
    "   - Splits the dataset into training and testing subsets.\n",
    "\n",
    "4. **`SVC`**:\n",
    "   - Support Vector Classifier, a powerful tool for binary classification.\n",
    "\n",
    "5. **`classification_report`**:\n",
    "   - Summarizes model performance with metrics like precision, recall, and F1-score.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example Run**\n",
    "\n",
    "#### Input Data (spam.csv):\n",
    "| v1   | v2                                     |\n",
    "|------|---------------------------------------|\n",
    "| ham  | Go until jurong point, crazy..        |\n",
    "| spam | Congratulations!!! You won Lottery...|\n",
    "\n",
    "#### Test Input:\n",
    "1. `\"Congratulations!!!, You won Lottery of $1500000000...\"` → Predicted: **Spam**\n",
    "2. `\"Go until jurong point, crazy..\"` → Predicted: **Ham**\n",
    "\n",
    "#### Classification Report Output:\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0       0.97      0.99      0.98       121\n",
    "         1       0.98      0.95      0.96        72\n",
    "\n",
    "    accuracy                           0.97       193\n",
    "   macro avg       0.97      0.97      0.97       193\n",
    "weighted avg       0.97      0.97      0.97       193\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Let me know if you have questions or need further clarifications!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299bd8c1-4c03-412e-aaf8-713e6f39295d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06913bc2-fb84-489a-a78e-0a3f673075ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
