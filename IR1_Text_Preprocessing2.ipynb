{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f2792b6",
   "metadata": {},
   "source": [
    "# Write a program for pre-processing of a text document such as stop word removal, stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d41ca0",
   "metadata": {},
   "source": [
    "### Libraries to use:\n",
    "- NLTK (Natural Language Toolkit): This library provides easy access to a collection of stopwords and stemming algorithms.\n",
    "- Stopwords: We’ll use NLTK's stopwords list.\n",
    "- Stemmer: We’ll use the PorterStemmer from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae4cf53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\omkar\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\omkar\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\omkar\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\omkar\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (2024.4.28)\n",
      "Requirement already satisfied: tqdm in c:\\users\\omkar\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\omkar\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\omkar\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\omkar\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -upyterlab (c:\\users\\omkar\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8166a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9947a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10061]\n",
      "[nltk_data]     No connection could be made because the target machine\n",
      "[nltk_data]     actively refused it>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do once\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e854ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize stopword list and stemmer\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "stemmer =PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51cb32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess function to remove stopwords and apply stemming\n",
    "def preprocess_text(text):\n",
    "    text=text.lower() #lower case\n",
    "    \n",
    "    #remove punctuations\n",
    "    text=text.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    \n",
    "    tokens= text.split() #split into words\n",
    "    \n",
    "    #remove stopwords and apply stemming\n",
    "    processed_tokens= [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return \" \".join(processed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "058aeb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = '''Read the migration plan to Notebook 7 to learn about the new features and the actions to take if you are using extensions - Please note that updating to Notebook 7 might break some of your extensions.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "015f72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the document\n",
    "processed_document = preprocess_text(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b84fe59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Document:\n",
      " Read the migration plan to Notebook 7 to learn about the new features and the actions to take if you are using extensions - Please note that updating to Notebook 7 might break some of your extensions.\n",
      "\n",
      "Processed Document:\n",
      " read migrat plan notebook 7 learn new featur action take use extens pleas note updat notebook 7 might break extens\n"
     ]
    }
   ],
   "source": [
    "# Output the original and processed text\n",
    "print(\"Original Document:\\n\", document)\n",
    "print(\"\\nProcessed Document:\\n\", processed_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256bed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "### **Explanation of the Code and Outputs**\n",
    "\n",
    "This program **preprocesses a text document** by removing stopwords and applying stemming. Here’s a detailed explanation:\n",
    "\n",
    "---\n",
    "\n",
    "### **Code Breakdown**\n",
    "\n",
    "#### **1. Library Imports and Downloads**\n",
    "```python\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "```\n",
    "\n",
    "- **`nltk` (Natural Language Toolkit)**: A Python library for processing text data.\n",
    "- **Stopwords**: Common words in a language (e.g., \"and\", \"the\", \"is\") that don’t contribute much meaning.\n",
    "- **PorterStemmer**: A tool to reduce words to their root forms (e.g., \"running\" → \"run\").\n",
    "- **Punctuation Removal**: Helps clean the text by removing characters like \".\", \",\", \"?\".\n",
    "- **`nltk.download('stopwords')`**: Downloads the list of stopwords for English.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Preprocessing Function**\n",
    "```python\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert text to lowercase\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Remove punctuation\n",
    "    tokens = text.split()  # Split text into words (tokens)\n",
    "    processed_tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]  # Remove stopwords and apply stemming\n",
    "    return \" \".join(processed_tokens)  # Join processed words back into a string\n",
    "```\n",
    "\n",
    "- **Lowercase Conversion**: Ensures all words are treated uniformly (e.g., \"The\" and \"the\").\n",
    "- **Punctuation Removal**: Eliminates unnecessary characters.\n",
    "- **Tokenization**: Breaks the text into individual words.\n",
    "- **Stopword Removal**: Filters out common, meaningless words using `stop_words`.\n",
    "- **Stemming**: Reduces words to their root forms.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Input Document**\n",
    "```python\n",
    "document = '''Read the migration plan to Notebook 7 to learn about the new features and the actions to take if you are using extensions - Please note that updating to Notebook 7 might break some of your extensions.'''\n",
    "```\n",
    "\n",
    "This is the raw input document that we want to preprocess.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Processed Document**\n",
    "```python\n",
    "processed_document = preprocess_text(document)\n",
    "```\n",
    "\n",
    "The `preprocess_text` function processes the input and returns the cleaned-up version.\n",
    "\n",
    "---\n",
    "\n",
    "### **Output Explanation**\n",
    "\n",
    "#### **Original Document**\n",
    "```\n",
    "Read the migration plan to Notebook 7 to learn about the new features and the actions to take if you are using extensions - Please note that updating to Notebook 7 might break some of your extensions.\n",
    "```\n",
    "\n",
    "This is the original text, containing:\n",
    "- Mixed case words.\n",
    "- Punctuation marks.\n",
    "- Stopwords (e.g., \"the\", \"to\", \"and\").\n",
    "- Inflected words (e.g., \"updating\", \"features\").\n",
    "\n",
    "---\n",
    "\n",
    "#### **Processed Document**\n",
    "```\n",
    "read migrat plan notebook 7 learn new featur action take use extens pleas note updat notebook 7 might break extens\n",
    "```\n",
    "\n",
    "After preprocessing:\n",
    "1. **Lowercase Conversion**: All words are lowercase (e.g., \"Read\" → \"read\").\n",
    "2. **Punctuation Removed**: Characters like \".\", \",\", \"-\" are gone.\n",
    "3. **Stopwords Removed**: Words like \"the\", \"to\", \"if\" are eliminated.\n",
    "4. **Stemming Applied**: \n",
    "   - \"migration\" → \"migrat\".\n",
    "   - \"features\" → \"featur\".\n",
    "   - \"using\" → \"use\".\n",
    "\n",
    "---\n",
    "\n",
    "### **Purpose of Preprocessing**\n",
    "1. **Stopword Removal**: Focuses on meaningful words, improving analysis and reducing noise.\n",
    "2. **Stemming**: Groups related words (e.g., \"run\", \"running\", \"runner\") into a single base form, improving consistency.\n",
    "3. **Clean Text**: Simplifies the text for further processing in tasks like text classification or sentiment analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Concepts**\n",
    "\n",
    "#### **Stopwords**\n",
    "- Words that are common but don’t add significant meaning to a sentence.\n",
    "- Example: \"the\", \"is\", \"and\", \"a\".\n",
    "\n",
    "#### **Stemming**\n",
    "- Reduces words to their root form using algorithms.\n",
    "- Example: \"running\", \"runner\", \"runs\" → \"run\".\n",
    "\n",
    "#### **Why Preprocess?**\n",
    "- Preprocessing is essential for preparing text data for **machine learning** models, **sentiment analysis**, or **text summarization**.\n",
    "- Removes irrelevant parts of text and normalizes it for consistent representation.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
